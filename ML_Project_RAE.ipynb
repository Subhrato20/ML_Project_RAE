{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_Project_RAE.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpXx6y8BddEi",
        "outputId": "a35f94f6-94b3-4bbc-cf0a-e97c1ef6265f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive._mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8AYvv4ode-u"
      },
      "source": [
        "import os\n",
        "import logging\n",
        "\n",
        "import pandas as pd\n",
        "import tensorflow.keras as keras\n",
        "\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "# Log setting\n",
        "logging.basicConfig(format=\"%(asctime)s %(levelname)s %(message)s\", datefmt=\"%H:%M:%S\", level=logging.INFO)\n",
        "\n",
        "# Change display.max_rows to show all features.\n",
        "pd.set_option(\"display.max_rows\", 85)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTlBbvJRdhQX"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XreR2gNsdncz"
      },
      "source": [
        "training_df = pd.read_csv('/content/drive/MyDrive/train_MachineLearningCVE.csv', skipinitialspace=True)\n",
        "testing_df = pd.read_csv('/content/drive/MyDrive/test_MachineLearningCVE.csv', skipinitialspace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAw7tTAndpvB",
        "outputId": "fb318061-30eb-447e-e857-2dd4494a6939"
      },
      "source": [
        "print(\"Training set has {} rows.\".format(len(training_df)))\n",
        "print(\"Testing set has {} rows.\".format(len(testing_df)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set has 2264594 rows.\n",
            "Testing set has 566149 rows.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7_Urn-3dsoo"
      },
      "source": [
        "\n",
        "# Our new labels\n",
        "classes=[\"Normal\",\"Benign\",\"FTP-Patator\",\"SSH-Patator\",\"DoS slowloris\",\"DoS Slowhttptest\",\"DoS Hulk\",\"DoS GoldenEye\",\"Heartbleed\",\"Web Attack–Brute force\",\"Web Attack–XSS\",\"Web Attack–SQL Injection\",\"Infiltration\",\"Bot\",\"DDoS\",\"Port scan\"]\n",
        "\n",
        "#Helper function to label samples to 5 classes\n",
        "def label_attack (row):\n",
        "    if row[\"Label\"] == 0:\n",
        "        return classes[1]\n",
        "    if row[\"Label\"] == 1:\n",
        "        return classes[2]\n",
        "    if row[\"Label\"] == 2:\n",
        "        return classes[3]\n",
        "    if row[\"Label\"] == 3:\n",
        "        return classes[4]\n",
        "    if row[\"Label\"] == 4:\n",
        "        return classes[5]\n",
        "    if row[\"Label\"] == 4:\n",
        "        return classes[5]\n",
        "    if row[\"Label\"] == 5:\n",
        "        return classes[6]\n",
        "    if row[\"Label\"] == 6:\n",
        "        return classes[7]\n",
        "    if row[\"Label\"] == 7:\n",
        "        return classes[8]\n",
        "    if row[\"Label\"] == 8:\n",
        "        return classes[9]\n",
        "    if row[\"Label\"] == 9:\n",
        "        return classes[10]\n",
        "    if row[\"Label\"] == 10:\n",
        "        return classes[11]\n",
        "    if row[\"Label\"] == 11:\n",
        "        return classes[12]\n",
        "    if row[\"Label\"] == 12:\n",
        "        return classes[13]\n",
        "    if row[\"Label\"] == 13:\n",
        "        return classes[14]\n",
        "    if row[\"Label\"] == 12:\n",
        "        return classes[13]\n",
        "    if row[\"Label\"] == 13:\n",
        "        return classes[14]\n",
        "    if row[\"Label\"] == 14:\n",
        "        return classes[15]\n",
        "    return classes[0]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbynHjM9dt8k"
      },
      "source": [
        "test_samples_length = len(testing_df)\n",
        "df=pd.concat([training_df,testing_df])\n",
        "df[\"Class\"]=df.apply(label_attack,axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDuQMD77dx7Y"
      },
      "source": [
        "df=df.drop(\"Label\",axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lebOZy7yd1G6"
      },
      "source": [
        "training_df= df.iloc[:-test_samples_length, :]\n",
        "testing_df= df.iloc[-test_samples_length:,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BB1uycGMd3Gk",
        "outputId": "00b4ed96-d7c9-40c9-a93f-cc0bb0cac951"
      },
      "source": [
        "training_outcomes=training_df[\"Class\"].unique()\n",
        "testing_outcomes=testing_df[\"Class\"].unique()\n",
        "print(\"The training set has {} possible outcomes \\n\".format(len(training_outcomes)) )\n",
        "print(\", \".join(training_outcomes)+\".\")\n",
        "print(\"\\nThe testing set has {} possible outcomes \\n\".format(len(testing_outcomes)))\n",
        "print(\", \".join(testing_outcomes)+\".\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The training set has 15 possible outcomes \n",
            "\n",
            "Benign, Web Attack–SQL Injection, DoS Slowhttptest, Heartbleed, DoS slowloris, DoS Hulk, DoS GoldenEye, Infiltration, FTP-Patator, Bot, Port scan, Web Attack–XSS, Web Attack–Brute force, DDoS, SSH-Patator.\n",
            "\n",
            "The testing set has 15 possible outcomes \n",
            "\n",
            "Benign, DoS Slowhttptest, Web Attack–SQL Injection, DoS slowloris, Heartbleed, DoS GoldenEye, DoS Hulk, Infiltration, Bot, FTP-Patator, Port scan, Web Attack–XSS, Web Attack–Brute force, DDoS, SSH-Patator.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vo7X0s0hd5_U"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import tensorflow as tf\n",
        "#tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "import itertools\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score,recall_score,precision_score,f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.layers import Input,Dropout,Dense\n",
        "from keras.models import Model\n",
        "from keras import regularizers\n",
        "from keras.utils.data_utils import get_file\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTjRBvuxd9xl"
      },
      "source": [
        "# Helper function for scaling continous values\n",
        "def minmax_scale_values(training_df,testing_df, col_name):\n",
        "    scaler = MinMaxScaler()\n",
        "    scaler = scaler.fit(training_df[col_name].values.reshape(-1, 1))\n",
        "    train_values_standardized = scaler.transform(training_df[col_name].values.reshape(-1, 1))\n",
        "    training_df[col_name] = train_values_standardized\n",
        "    test_values_standardized = scaler.transform(testing_df[col_name].values.reshape(-1, 1))\n",
        "    testing_df[col_name] = test_values_standardized\n",
        "    \n",
        "    \n",
        "#Helper function for one hot encoding\n",
        "def encode_text(training_df,testing_df, name):\n",
        "    training_set_dummies = pd.get_dummies(training_df[name])\n",
        "    testing_set_dummies = pd.get_dummies(testing_df[name])\n",
        "    for x in training_set_dummies.columns:\n",
        "        dummy_name = \"{}_{}\".format(name, x)\n",
        "        training_df[dummy_name] = training_set_dummies[x]\n",
        "        if x in testing_set_dummies.columns :\n",
        "            testing_df[dummy_name]=testing_set_dummies[x]\n",
        "        else :\n",
        "            testing_df[dummy_name]=np.zeros(len(testing_df))\n",
        "    training_df.drop(name, axis=1, inplace=True)\n",
        "    testing_df.drop(name, axis=1, inplace=True)\n",
        "    \n",
        "    \n",
        "sympolic_columns=[\"protocol_type\",\"service\",\"flag\"]\n",
        "label_column=\"Class\"\n",
        "for column in df.columns :\n",
        "    if column in sympolic_columns:\n",
        "        encode_text(training_df,testing_df,column)\n",
        "    elif not column == label_column:\n",
        "        minmax_scale_values(training_df,testing_df, column)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQpvr0VbeBDW"
      },
      "source": [
        "x,y=training_df,training_df.pop(\"Class\").values\n",
        "x=x.values\n",
        "x_test,y_test=testing_df,testing_df.pop(\"Class\").values\n",
        "x_test=x_test.values\n",
        "y0=np.ones(len(y),np.int8)\n",
        "y0[np.where(y==classes[0])]=0\n",
        "y0_test=np.ones(len(y_test),np.int8)\n",
        "y0_test[np.where(y_test==classes[0])]=0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYA8ZoLeeFw-"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from keras.layers import Input, Dense, Dropout\n",
        "from keras.models import Model\n",
        "from keras import regularizers\n",
        "\n",
        "import tqdm\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WHJblAUeK3e"
      },
      "source": [
        "from keras.losses import binary_crossentropy, mean_squared_error\n",
        "from keras import backend as K\n",
        "\n",
        "def L(X, X_, t):\n",
        "  if t == 'binary':\n",
        "    return binary_crossentropy(X, X_)\n",
        "  return mean_squared_error(X, X_)\n",
        "\n",
        "def R(X):\n",
        "  return K.dot(X, K.transpose(X))\n",
        "\n",
        "def tau(X, t):\n",
        "  return tf.where(X < t, X, tf.zeros(tf.shape(X)))\n",
        "\n",
        "def rae_loss(alpha, t, L_type='binary'):\n",
        "  def rae(y_true, y_pred):\n",
        "    return (1 - alpha)*L(y_true, y_pred, L_type) + alpha*L(tau(R(y_true), t), tau(R(y_pred), t), L_type)\n",
        "  return rae"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0pkg3UJeOB4"
      },
      "source": [
        "def plot_digits(n, X, decoded_X):\n",
        "    plt.figure(figsize=(2*n, 4))\n",
        "    for i in range(n):\n",
        "        ax = plt.subplot(2, n, i + 1)\n",
        "        plt.imshow(X[i].reshape(28, 28))\n",
        "        plt.gray()\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "\n",
        "        ax = plt.subplot(2, n, i + 1 + n)\n",
        "        plt.imshow(decoded_X[i].reshape(28, 28))\n",
        "        plt.gray()\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmAbRVPqeQrX"
      },
      "source": [
        "inputs = Input(shape=(78,))\n",
        "\n",
        "encoded = Dense(units=128, activation='relu')(inputs)\n",
        "\n",
        "encoded = Dense(units=64, activation='relu')(encoded)\n",
        "\n",
        "encoded = Dense(units=2, activation='relu')(encoded)\n",
        "\n",
        "decoded = Dense(units=64, activation='relu')(encoded)\n",
        "\n",
        "decoded = Dense(units=128, activation='relu')(decoded)\n",
        "\n",
        "decoded = Dense(units=78, activation='sigmoid')(decoded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHgjgTxeeeX2"
      },
      "source": [
        "autoencoder = Model(inputs, decoded)\n",
        "encoder = Model(inputs, encoded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RexwQ4C_ejuW",
        "outputId": "2044d856-0a5c-4175-de46-e425a3538d77"
      },
      "source": [
        "autoencoder.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 78)]              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               10112     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 2)                 130       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 64)                192       \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 128)               8320      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 78)                10062     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 37,072\n",
            "Trainable params: 37,072\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9plvqLxeqIn",
        "outputId": "bc439763-fe8a-4049-edfa-752dad32dd13"
      },
      "source": [
        "alphas = np.linspace(0, 1, 4)\n",
        "t = 1\n",
        "losses = []\n",
        "\n",
        "for alpha in alphas:\n",
        "    loss = rae_loss(alpha, t, 'binary')\n",
        "    autoencoder.compile(optimizer='adam', loss=loss)\n",
        "    \n",
        "    print('Alpha {}'.format(alpha))\n",
        "    \n",
        "    h = autoencoder.fit(x[np.where(y0==1)],x[np.where(y0==1)],\n",
        "                    epochs=2,\n",
        "                    batch_size=100,\n",
        "                    shuffle=True, \n",
        "                    validation_split=0.1)\n",
        "    \n",
        "    losses.append(h.history['val_loss'][-1])\n",
        "    print(h.history['val_loss'][-1])\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alpha 0.0\n",
            "Epoch 1/2\n",
            "20382/20382 [==============================] - 87s 4ms/step - loss: 0.0487 - val_loss: 0.0628\n",
            "Epoch 2/2\n",
            "20382/20382 [==============================] - 84s 4ms/step - loss: 0.0449 - val_loss: 0.0602\n",
            "0.060158323496580124\n",
            "Alpha 0.3333333333333333\n",
            "Epoch 1/2\n",
            "20382/20382 [==============================] - 86s 4ms/step - loss: 0.1162 - val_loss: 0.1381\n",
            "Epoch 2/2\n",
            "20382/20382 [==============================] - 86s 4ms/step - loss: 0.1132 - val_loss: 0.1396\n",
            "0.1395607888698578\n",
            "Alpha 0.6666666666666666\n",
            "Epoch 1/2\n",
            "20382/20382 [==============================] - 90s 4ms/step - loss: 0.1491 - val_loss: 0.1668\n",
            "Epoch 2/2\n",
            "20382/20382 [==============================] - 87s 4ms/step - loss: 0.1487 - val_loss: 0.1649\n",
            "0.1649409979581833\n",
            "Alpha 1.0\n",
            "Epoch 1/2\n",
            "20382/20382 [==============================] - 86s 4ms/step - loss: 0.1773 - val_loss: 0.1894\n",
            "Epoch 2/2\n",
            "20382/20382 [==============================] - 94s 5ms/step - loss: 0.1769 - val_loss: 0.1922\n",
            "0.1921989917755127\n"
          ]
        }
      ]
    }
  ]
}